<!DOCTYPE html>
<html>

    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Hugo Nicolau's personal webpage. Hugo is an Assistant Professor in the Computer Science and Engineering Department (DEI) of Instituto Superior Técnico, University of Lisbon in Portugal. He's also a researcher at the Visualization and Intelligent Multimodal Interfaces (VIMMI) group at INESC-ID. His research interests include human-computer interaction, accessibility, and user-centred design, focusing on the design, development, and evaluation of novel mobile and ubiquitous computing applications.">
    <meta name="author" content="Hugo Nicolau">
    <link rel="shortcut icon" href="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/ico/favicon.ico">

    <title>HUGO NICOLAU - Non-Visual Mobile Text-Entry</title>

    <!-- Bootstrap core CSS -->
    <link href="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/css/bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/css/style.css" rel="stylesheet">
    <link href="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/css/font-awesome.min.css" rel="stylesheet">
    
</head>

    <body>
        <!-- Fixed navbar -->
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="http://web.tecnico.ulisboa.pt/hugo.nicolau/">HUGO NICOLAU</a>
    </div>
    <div class="navbar-collapse collapse navbar-right">
      <ul class="nav navbar-nav">
        <li ><a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/">HOME</a></li>
        <li ><a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/">PUBLICATIONS</a></li>
        <li ><a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/aboutme/">ABOUT ME</a></li>
      </ul>
    </div><!--/.nav-collapse -->
  </div>
</div>

            <div id="blue">
    <div class="container">
        <div class="row">
            <h3>Non-Visual Mobile Text-Entry</h3>
        </div><!-- /row -->
    </div> <!-- /container -->
</div><!-- /blue -->

<div class="container">
    <div class="row">

        <div class="col-lg-10 col-lg-offset-1 centered">
    <div id="carousel-example-generic" class="carousel slide" data-ride="carousel">
        <!-- Indicators -->
        <ol class="carousel-indicators">
            
                <li data-target="#carousel-example-generic" data-slide-to="0" 
                
                    class="active"
                >
                </li>
            
                <li data-target="#carousel-example-generic" data-slide-to="1" 
                >
                </li>
            
        </ol>

        <!-- Wrapper for slides -->
        <div class="carousel-inner">
            
                <div class="item active">
                    <img src="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/img/project/carousel/textentry_01.jpg" alt="">
                </div>
            
            
                <div class="item">
                    <img src="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/img/project/carousel/textentry_02.png" alt="">
                </div>
            
        </div>
    </div> <!--/Carousel -->
</div>


        <div class="col-lg-5 col-lg-offset-1">
            <div class="spacing"></div>

            <p>Since the advent of Apple’s iPhone and its built-in accessibility features, blind people have increased access to mainstream mobile applications. However, the flat surface poses challenges that are only partially solved. Particularly, typing is still slow compared to what sighted people experience.</p>

<p>In this research project we are creating novel non-visual input methods to touch-based form-factors: from tablets to smartwatches.</p>


        </div>
        <div class="col-lg-4 col-lg-offset-1">
            <div class="spacing"></div>
            <h4>Project Details</h4>
            <div class="hline"></div>
            <p><b>Title:</b> Non-Visual Mobile Text-Entry</p>
            <p><b>Date:</b> Jan 1, 2017</p>
            <p><b>Authors:</b> Hugo Nicolau, Tiago Guerreiro, Kyle Montague, João Guerreiro</p>
            <!--<p><b>Categories:</b> project</p>-->
            <p><b>Keywords:</b> touchscreen, text-entry, blind, mobile</p>
            <!--<p><b>Client:</b> </p>-->
            
        </div>
    </div><! --/row -->
    
    <br/>
    <div class="row">
        <div class="col-lg-10 col-lg-offset-1">
            <h4>Related Publications</h4>
            <ul class="bibliography"><li><br />

<ul class="reference">
    <li class="pub-title">
        <b>Hybrid-Brailler: Combining Physical and Gestural Interaction for Mobile Braille Input and Editing</b>
        
        
    </li>
    <li>Trindade, Daniel and Rodrigues, André and Guerreiro, Tiago and Nicolau, Hugo</li> <!-- TODO order of names -->
    <li><i>Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, 27:1–27:12, 2018</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Trindade-CHI-2018')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2018/Trindade-CHI-2018.pdf">PDF</a>]
        [<a href="http://doi.acm.org/10.1145/3173574.3173601">LIBRARY</a>]
        [<a href="https://www.youtube.com/watch?v=_hmI9IRBPfs">VIDEO</a>]
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Trindade-CHI-2018" class="pub-abstract"><p>Braille input enables fast nonvisual entry speeds on mobile touchscreen devices. Yet, the lack of tactile cues commonly results in typing errors, which are hard to correct. We propose Hybrid-Brailler, an input solution that combines physical and gestural interaction to provide fast and accurate Braille input. We use the back of the device for physical chorded input while freeing the touchscreen for gestural interaction. Gestures are used in editing operations, such as caret movement, text selection, and clipboard control, enhancing the overall text entry experience. We conducted two user studies to assess both input and editing performance. Results show that Hybrid-Brailler supports fast entry rates as its virtual counterpart, while significantly increasing input accuracy. Regarding editing performance, when compared with the mainstream technique, Hybrid-Brailler shows performance benefits of 21% in speed and increased editing accuracy. We finish with lessons learned for designing future nonvisual input and editing techniques.</p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>Effect of Target Size on Non-visual Text-entry</b>
        
        <span class="pub-award">Honorable Mention</span>
    </li>
    <li>Rodrigues, André and Nicolau, Hugo and Montague, Kyle and Carriço, Luı́s and Guerreiro, Tiago</li> <!-- TODO order of names -->
    <li><i>Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services, 47–52, 2016</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Rodrigues-MHCI-2016')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2016/Rodrigues-MHCI-2016.pdf">PDF</a>]
        [<a href="http://doi.acm.org/10.1145/2935334.2935376">LIBRARY</a>]
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Rodrigues-MHCI-2016" class="pub-abstract"><p>Touch-enabled devices have a growing variety of screen sizes; however, there is little knowledge on the effect of key size on non-visual text-entry performance. We conducted a user study with 12 blind participants to investigate how non-visual input performance varies with four QWERTY keyboard sizes (ranging from 15mm to 2.5mm). This paper presents an analysis of typing performance and touch behaviors discussing its implications for future research. Our findings show that there is an upper limit to the benefits of larger target sizes between 10mm and 15mm. Input speed decreases from 4.5 to 2.4 words per minute (WPM) for targets sizes below 10mm. The smallest size was deemed unusable by participants even though performance was in par with previous work.</p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>Towards Inviscid Text-Entry for Blind People through Non-Visual Word Prediction Interfaces.</b>
        
        
    </li>
    <li>Montague, Kyle and Guerreiro, João and Nicolau, Hugo and Guerreiro, Tiago and Rodrigues, André and Gonçalves, Daniel</li> <!-- TODO order of names -->
    <li><i>Inviscid Text-Entry and Beyond Workshop at Conference on Human Factors in Computing Systems (CHI), , 2016</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Montague-CHI-2016')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2016/Montague-CHI-2016.pdf">PDF</a>]
        
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Montague-CHI-2016" class="pub-abstract"><p>Word prediction can significantly improve text-entry rates on mobile touchscreen devices. However, these interactions are inherently visual and require constant scanning for new word predictions to actually take advantage of the suggestions. In this paper, we discuss the design space for non-visual word prediction interfaces and finally present Shout-out Suggestions, a novel interface to provide non-visual access to word predictions on existing mobile devices.</p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>Typing Performance of Blind Users: An Analysis of Touch Behaviors, Learning Effect, and In-Situ Usage</b>
        
        
    </li>
    <li>Nicolau, Hugo and Montague, Kyle and Guerreiro, Tiago and Rodrigues, André and Hanson, Vicki L.</li> <!-- TODO order of names -->
    <li><i>Proceedings of the 17th International ACM SIGACCESS Conference on Computers &#38; Accessibility, 273–280, 2015</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Nicolau-ASSETS-2015')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2015/Nicolau-ASSETS-2015.pdf">PDF</a>]
        [<a href="http://doi.acm.org/10.1145/2700648.2809861">LIBRARY</a>]
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Nicolau-ASSETS-2015" class="pub-abstract"><p>Non-visual text-entry for people with visual impairments has focused mostly on the comparison of input techniques reporting on performance measures, such as accuracy and speed. While researchers have been able to establish that non-visual input is slow and error prone, there is little understanding on how to improve it. To develop a richer characterization of typing performance, we conducted a longitudinal study with five novice blind users. For eight weeks, we collected in-situ usage data and conducted weekly laboratory assessment sessions. This paper presents a thorough analysis of typing performance that goes beyond traditional aggregated measures of text-entry and reports on character-level errors and touch measures. Our findings show that users improve over time, even though it is at a slow rate (0.3 WPM per week). Substitutions are the most common type of error and have a significant impact on entry rates. In addition to text input data, we analyzed touch behaviors, looking at touch contact points, exploration movements, and lift positions. We provide insights on why and how performance improvements and errors occur. Finally, we derive some implications that should inform the design of future virtual keyboards for non-visual input</p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>TabLETS Get Physical: Non-Visual Text Entry on Tablet Devices</b>
        
        
    </li>
    <li>Guerreiro, João and Rodrigues, André and Montague, Kyle and Guerreiro, Tiago and Nicolau, Hugo and Gonçalves, Daniel</li> <!-- TODO order of names -->
    <li><i>Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, 39–42, 2015</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Guerreiro-CHI-2015')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2015/Guerreiro-CHI-2015.pdf">PDF</a>]
        [<a href="http://doi.acm.org/10.1145/2702123.2702373">LIBRARY</a>]
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Guerreiro-CHI-2015" class="pub-abstract"><p>Tablet devices can display full-size QWERTY keyboards similar to the physical ones. Yet, the lack of tactile feedback and the inability to rest the fingers on the home keys result in a highly demanding and slow exploration task for blind users. We present SpatialTouch, an input system that leverages previous experience with physical QWERTY keyboards, by supporting two-handed interaction through multitouch exploration and spatial, simultaneous audio feedback. We conducted a user study, with 30 novice touchscreen participants entering text under one of two conditions: (1) SpatialTouch or (2) mainstream accessibility method Explore by Touch. We show that SpatialTouch enables blind users to leverage previous experience as they do a better use of home keys and perform more efficient exploration paths. Results suggest that although SpatialTouch did not result in faster input rates overall, it was indeed able to leverage previous QWERTY experience in contrast to Explore by Touch.</p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>B#: Chord-based Correction for Multitouch Braille Input</b>
        
        
    </li>
    <li>Nicolau, Hugo and Montague, Kyle and Guerreiro, Tiago and Guerreiro, João and Hanson, Vicki L.</li> <!-- TODO order of names -->
    <li><i>Proceedings of the 32Nd Annual ACM Conference on Human Factors in Computing Systems, 1705–1708, 2014</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Nicolau-CHI-2014')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2014/Nicolau-CHI-2014.pdf">PDF</a>]
        [<a href="http://doi.acm.org/10.1145/2556288.2557269">LIBRARY</a>]
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Nicolau-CHI-2014" class="pub-abstract"><p>Braille has paved its way into mobile touchscreen devices, providing faster text input for blind people. This advantage comes at the cost of accuracy, as chord typing over a flat surface has proven to be highly error prone. A misplaced finger on the screen translates into a different or unrecognized character. However, the chord itself gathers information that can be leveraged to improve input performance. We present B#, a novel correction system for multitouch Braille input that uses chords as the atomic unit of information rather than characters. Experimental results on data collected from 11 blind people revealed that B# is effective in correcting errors at character-level, thus providing opportunities for instant corrections of unrecognized chords; and at word-level, where it outperforms a popular spellchecker by providing correct suggestions for 72% of incorrect words (against 38%). We finish with implications for designing chord-based correction system and avenues for future work.</p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>Mobile Text-Entry: The Unattainable Ultimate Method</b>
        
        
    </li>
    <li>Guerreiro, Tiago and Nicolau, Hugo and Jorge, Joaquim and Gonçalves, Daniel</li> <!-- TODO order of names -->
    <li><i>Frontiers in Accessibility for Pervasive Computing Workshop at Pervasive, , 2012</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Guerreiro-Pervasive-2012')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2012/Guerreiro-Pervasive-2012.pdf">PDF</a>]
        
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Guerreiro-Pervasive-2012" class="pub-abstract"><p>There is no such thing as an ultimate text-entry method. People are diverse and mobile touch typing takes place in many different places and scenarios. This translates to a wide and dynamic diversity of abilities. Conversely, different methods present different demands and are adequate to different people / situations. In this paper we focus our attention on blind and situationally blind people; how abilities differ between people and situations, and how we can cope with those differences either by varying or adapting methods. Our research goal is to identify the human abilities that influence mobile text-entry and match them with methods (and underlying demands) in a comprehensive and extensible design space. </p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>Blind People and Mobile Touch-based Text-entry: Acknowledging the Need for Different Flavors</b>
        
        <span class="pub-award">Best Student Paper Award</span>
    </li>
    <li>Oliveira, João and Guerreiro, Tiago and Nicolau, Hugo and Jorge, Joaquim and Gonçalves, Daniel</li> <!-- TODO order of names -->
    <li><i>The Proceedings of the 13th International ACM SIGACCESS Conference on Computers and Accessibility, 179–186, 2011</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Oliveira-ASSETS-2011')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2011/Oliveira-ASSETS-2011.pdf">PDF</a>]
        [<a href="http://doi.acm.org/10.1145/2049536.2049569">LIBRARY</a>]
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Oliveira-ASSETS-2011" class="pub-abstract"><p>The emergence of touch-based mobile devices brought fresh and exciting possibilities. These came at the cost of a considerable number of novel challenges. They are particularly apparent with the blind population, as these devices lack tactile cues and are extremely visually demanding. Existing solutions resort to assistive screen reading software to compensate the lack of sight, still not all the information reaches the blind user. Good spatial ability is still required to have notion of the device and its interface, as well as the need to memorize buttons‟ position on screen. These abilities, as many other individual attributes as age, age of blindness onset or tactile sensibility are often forgotten, as the blind population is presented with the same methods ignoring capabilities and needs. Herein, we present a study with 13 blind people consisting of a touch screen text-entry task with four different methods. Results show that different capability levels have significant impact on performance and that this impact is related with the different methods‟ demands. These variances acknowledge the need of accounting for individual characteristics and giving space for difference, towards inclusive design.</p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>BrailleType: Unleashing Braille over Touch Screen Mobile Phones</b>
        
        <span class="pub-award">People’s Choice Award</span>
    </li>
    <li>Oliveira, João and Guerreiro, Tiago and Nicolau, Hugo and Jorge, Joaquim and Gonçalves, Daniel</li> <!-- TODO order of names -->
    <li><i>Human-Computer Interaction – INTERACT 2011: 13th IFIP TC 13 International Conference, Lisbon, Portugal, September 5-9, 2011, Proceedings, Part I, 100–107, 2011</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Oliveira-INTERACT-2011')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2011/Oliveira-INTERACT-2011.pdf">PDF</a>]
        [<a href="http://dx.doi.org/10.1007/978-3-642-23774-4_10">LIBRARY</a>]
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Oliveira-INTERACT-2011" class="pub-abstract"><p>The emergence of touch screen devices poses a new set of challenges regarding text-entry. These are more obvious when considering blind people, as touch screens lack the tactile feedback they are used to when interacting with devices. The available solutions to enable non-visual text-entry resort to a wide set of targets, complex interaction techniques or unfamiliar layouts. We propose BrailleType, a text-entry method based on the Braille alphabet. BrailleType avoids multi-touch gestures in favor of a more simple single-finger interaction, featuring few and large targets. We performed a user study with fifteen blind subjects, to assess this method’s performance against Apple’s VoiceOver approach. BrailleType although slower, was significantly easier and less error prone. Results suggest that the target users would have a smoother adaptation to BrailleType than to other more complex methods.</p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>Proficient Blind Users and Mobile Text-entry</b>
        
        
    </li>
    <li>Nicolau, Hugo and Guerreiro, Tiago and Jorge, Joaquim and Gonçalves, Daniel</li> <!-- TODO order of names -->
    <li><i>Proceedings of the 28th Annual European Conference on Cognitive Ergonomics, 19–22, 2010</i></li>
    <li>
        
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2010/Nicolau-ECCE-2010.pdf">PDF</a>]
        [<a href="http://doi.acm.org/10.1145/1962300.1962307">LIBRARY</a>]
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Nicolau-ECCE-2010" class="pub-abstract"><p></p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>From tapping to touching: Making touch screens accessible to blind users</b>
        
        
    </li>
    <li>Guerreiro, Tiago and Nicolau, Hugo and Jorge, Joaquim A</li> <!-- TODO order of names -->
    <li><i>IEEE Multimedia, , 2008</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Guerreiro-IEEE-2008')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2008/Guerreiro-IEEE-2008.pdf">PDF</a>]
        
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Guerreiro-IEEE-2008" class="pub-abstract"><p>Mobile phones play an important role in modern society. Their applications extend beyond basic communications, ranging from productivity to leisure. However, most tasks beyond making a call require significant visual skills. While screen-reading applications make text more accessible, most interaction, such as menu navigation and especially text entry, requires hand–eye coordination, making it difficult for blind users to interact with mobile devices and execute tasks. Although solutions exist for people with special needs, these are expensive and cumbersome, and software approaches require adaptations that remain ineffective, difficult to learn, and error prone. Recently, touch-screen equipped mobile phones, such as the iPhone, have become popular. The ability to directly touch and manipulate data on the screen without using any intermediary devices has a strong appeal, but the possibilities for blind users are at best limited. In this article, we describe NavTouch, a new, gesture-based, text-entry method developed to aid vision-impaired users with mobile devices that have touch screens. User evaluations show it is both easy to learn and more effective than previous approaches.</p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>Mobile Text-entry Models for People with Disabilities</b>
        
        
    </li>
    <li>Guerreiro, Tiago and Lagoá, Paulo and Nicolau, Hugo and Santana, Pedro and Jorge, Joaquim</li> <!-- TODO order of names -->
    <li><i>Proceedings of the 15th European Conference on Cognitive Ergonomics: The Ergonomics of Cool Interaction, 39:1–39:4, 2008</i></li>
    <li>
        
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2008/Guerreiro-ECCE-2008.pdf">PDF</a>]
        [<a href="http://doi.acm.org/10.1145/1473018.1473067">LIBRARY</a>]
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Guerreiro-ECCE-2008" class="pub-abstract"><p></p><div class="hline"></div></div>
</ul>

</li>
<li><br />

<ul class="reference">
    <li class="pub-title">
        <b>Acessibilidade Movel: Solucoes para Deficientes Visuais</b>
        <img class="pub-flag" src="../assets/img/pt.gif" alt="portuguese flag"/> 
        
    </li>
    <li>Lagoa, Paulo and Nicolau, Hugo and Guerreiro, Tiago and Gonçalves, Daniel and Jorge, Joaquim</li> <!-- TODO order of names -->
    <li><i>Proceedings of the 3rd National Conference on Human-Computer Interaction (Interaccao), , 2008</i></li>
    <li>
        [<a class="pub-abstract-link" onClick="toggleVisible('Lagoa-INTERACCAO-2008')">ABSTRACT</a>]
        [<a href="http://web.tecnico.ulisboa.pt/hugo.nicolau/publications/2008/Lagoa-INTERACCAO-2008.pdf">PDF</a>]
        
        
        <!-- TODO toggle bibtext -->
    </li>
    <div id="Lagoa-INTERACCAO-2008" class="pub-abstract"><p>Os dispositivos moveis desempenham um papel importante na sociedade moderna. As suas funcionalidades vão além da simples comunicação, juntando agora um grande leque de funcionalidades, sejam elas de lazer ou de cariz profissional. A interacção com estes dispositivos e visualmente exigente, dificultando ou impossibilitando os utilizadores invisuais de terem controlo sobre o seu dispositivo. Em particular, a introdução de texto, uma tarefa transversal a muitas aplicaçoes, e de difícil realização, uma vez que depende do retorno visual, tanto do teclado, como do ecrã. Assim, através da utilização de novos sistemas de introdução de texto, que exploram as capacidades dos utilizadores invisuais, o sistema apresentado neste artigo oferece-lhes a possibilidade de operarem diferentes tipos de dispositivos. Para alem dos telemóveis comuns, apresentamos também um método de interacção em dispositivos com ecrãs tácteis. Estudos com utilizadores invisuais validaram as abordagens propostas para os varios dispositivos que suplantam os métodos tradicionais ao nível do desempenho, aprendizagem e satisfação do utilizador-alvo.</p><div class="hline"></div></div>
</ul>

</li></ul>
        </div>
    </div>
</div><! --/container -->

        <div id="footerwrap">
    <div class="container">
        <div class="row">
            <div class="col-lg-4">
                <h4>About</h4>
                <div class="hline-w"></div>
                <p>Hugo is an Assistant Professor in the <a href='https://fenix.tecnico.ulisboa.pt/departamentos/dei'>Computer Science and Engineering Department (DEI)</a> of <a href='http://tecnico.ulisboa.pt/en/'>Instituto Superior Técnico</a>, <a href='http://www.ulisboa.pt/en/'>University of Lisbon</a> in Portugal. He's also a researcher at the <a href='https://vimmi.inesc-id.pt/'>Visualization and Intelligent Multimodal Interfaces (VIMMI)</a> group at <a href='http://inesc-id.pt/'>INESC-ID</a>.</p>
            </div>
            <div class="col-lg-4">
                <h4>Social Links</h4>
                <div class="hline-w"></div>
                <p>
                    
                        <a href="https://www.facebook.com/hugo.nicolau" class="btn-social btn-outline"><i class="fa fa-facebook"></i></a>
                    
                        <a href="http://twitter.com/hnicolau" class="btn-social btn-outline"><i class="fa fa-twitter"></i></a>
                    
                        <a href="http://pt.linkedin.com/in/hugonicolau" class="btn-social btn-outline"><i class="fa fa-linkedin"></i></a>
                    
                        <a href="https://github.com/hnicolau" class="btn-social btn-outline"><i class="fa fa-github"></i></a>
                    
                </p>
            </div>
            <div class="col-lg-4">
                <h4>My Office</h4>
                <div class="hline-w"></div>
                <p>
                    
                        Instituto Superior Técnico, <br>
                    
                        Computer Science and Engineering Department, <br>
                    
                        Room 2-N9.21 - TagusPark <br>
                    
                        Avenida Professor Cavaco Silva, <br>
                    
                        2744-016 Porto Salvo, <br>
                    
                        Portugal <br>
                    
                </p>
            </div>
        </div><! --/row -->
    </div><! --/container -->
</div><! --/footerwrap -->
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/js/bootstrap.min.js"></script>
<script src="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/js/retina-1.1.0.js"></script>
<script src="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/js/jquery.hoverdir.js"></script>
<script src="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/js/jquery.hoverex.min.js"></script>
<script src="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/js/jquery.prettyPhoto.js"></script>
<script src="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/js/jquery.isotope.min.js"></script>
<script src="http://web.tecnico.ulisboa.pt/hugo.nicolau/assets/js/custom.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');

</script>

<script>
// Portfolio
(function($) {
	"use strict";
	var $container = $('.portfolio'),
		$items = $container.find('.portfolio-item'),
		portfolioLayout = 'fitRows';
		
		if( $container.hasClass('portfolio-centered') ) {
			portfolioLayout = 'masonry';
		}
				
		$container.isotope({
			filter: '*',
			animationEngine: 'best-available',
			layoutMode: portfolioLayout,
			animationOptions: {
			duration: 750,
			easing: 'linear',
			queue: false
		},
		masonry: {
		}
		}, refreshWaypoints());
		
		function refreshWaypoints() {
			setTimeout(function() {
			}, 1000);   
		}
				
		$('nav.portfolio-filter ul a').on('click', function() {
				var selector = $(this).attr('data-filter');
				$container.isotope({ filter: selector }, refreshWaypoints());
				$('nav.portfolio-filter ul a').removeClass('active');
				$(this).addClass('active');
				return false;
		});
		
		function getColumnNumber() { 
			var winWidth = $(window).width(), 
			columnNumber = 1;
		
			if (winWidth > 1200) {
				columnNumber = 5;
			} else if (winWidth > 950) {
				columnNumber = 4;
			} else if (winWidth > 600) {
				columnNumber = 3;
			} else if (winWidth > 400) {
				columnNumber = 2;
			} else if (winWidth > 250) {
				columnNumber = 1;
			}
				return columnNumber;
			}       
			
			function setColumns() {
				var winWidth = $(window).width(), 
				columnNumber = getColumnNumber(), 
				itemWidth = Math.floor(winWidth / columnNumber);
				
				$container.find('.portfolio-item').each(function() { 
					$(this).css( { 
					width : itemWidth + 'px' 
				});
			});
		}
		
		function setPortfolio() { 
			setColumns();
			$container.isotope('reLayout');
		}
			
		$container.imagesLoaded(function () { 
			setPortfolio();
		});
		
		$(window).on('resize', function () { 
		setPortfolio();          
	});
})(jQuery);
</script>

<script>
    //bibliography
    function toggleVisible(id) {    
        var el = document.getElementById(id); 
        console.log(el.style.display);
        if (el.style.display == "block") {      
            el.style.display = "none";
        } 
        else {
            el.style.display = "block";
        }
    }

</script>
    </body>
</html>